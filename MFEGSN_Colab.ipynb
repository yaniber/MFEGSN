{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b54619af",
      "metadata": {
        "id": "b54619af"
      },
      "source": [
        "# MFEGSN ‚Äî Pipeline Colab (Marker + LangExtract)\n",
        "\n",
        "Notebook optimis√© pour une ex√©cution **pas √† pas** sur Google Colab.\n",
        "\n",
        "**üöÄ Optimisation:** Les mod√®les (~4GB) sont sauvegard√©s sur Google Drive apr√®s le premier t√©l√©chargement.\n",
        "Les sessions suivantes chargeront les mod√®les depuis Drive en quelques secondes.\n",
        "\n",
        "**Ordre recommand√©:** √âtapes 1 ‚Üí 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "014f8fe4",
      "metadata": {
        "id": "014f8fe4"
      },
      "source": [
        "## √âtape 1 ‚Äî Monter Google Drive\n",
        "**IMPORTANT:** Ex√©cutez cette cellule EN PREMIER pour permettre le cache des mod√®les."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "82dce4c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82dce4c1",
        "outputId": "a0ec9951-f2f0-4a90-8312-2132ae67c838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "============================================================\n",
            "‚úÖ Google Drive mont√©! \n",
            "============================================================\n",
            "üìÇ Cache Drive:  /content/drive/MyDrive/.mfegsn_cache\n",
            "üíæ Taille du cache: 3.53 GB\n",
            "üöÄ Mod√®les d√©j√† en cache!  Le chargement sera rapide.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Cr√©er le dossier de cache sur Drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# === CONFIGURATION DU CACHE ===\n",
        "DRIVE_CACHE_DIR = Path(\"/content/drive/MyDrive/.mfegsn_cache\")\n",
        "DRIVE_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Sous-dossiers pour chaque type de cache\n",
        "HF_CACHE_DRIVE = DRIVE_CACHE_DIR / \"huggingface\"\n",
        "TORCH_CACHE_DRIVE = DRIVE_CACHE_DIR / \"torch\"\n",
        "DATALAB_CACHE_DRIVE = DRIVE_CACHE_DIR / \"datalab\"\n",
        "\n",
        "for cache_dir in [HF_CACHE_DRIVE, TORCH_CACHE_DRIVE, DATALAB_CACHE_DRIVE]:\n",
        "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Configurer les variables d'environnement pour utiliser le cache Drive\n",
        "os. environ[\"HF_HOME\"] = str(HF_CACHE_DRIVE)\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = str(HF_CACHE_DRIVE)\n",
        "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = str(HF_CACHE_DRIVE)\n",
        "os.environ[\"TORCH_HOME\"] = str(TORCH_CACHE_DRIVE)\n",
        "os.environ[\"XDG_CACHE_HOME\"] = str(DRIVE_CACHE_DIR)\n",
        "\n",
        "# V√©rifier la taille du cache existant\n",
        "def get_dir_size(path):\n",
        "    total = 0\n",
        "    if path.exists():\n",
        "        for f in path.rglob(\"*\"):\n",
        "            if f.is_file():\n",
        "                total += f.stat().st_size\n",
        "    return total / 1e9\n",
        "\n",
        "cache_size = get_dir_size(DRIVE_CACHE_DIR)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ Google Drive mont√©! \")\n",
        "print(\"=\"*60)\n",
        "print(f\"üìÇ Cache Drive:  {DRIVE_CACHE_DIR}\")\n",
        "print(f\"üíæ Taille du cache: {cache_size:.2f} GB\")\n",
        "if cache_size > 3:\n",
        "    print(\"üöÄ Mod√®les d√©j√† en cache!  Le chargement sera rapide.\")\n",
        "else:\n",
        "    print(\"üì• Premier lancement:  les mod√®les seront t√©l√©charg√©s et mis en cache.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c063508",
      "metadata": {
        "id": "3c063508"
      },
      "source": [
        "## √âtape 2 ‚Äî Installer les d√©pendances\n",
        "Installation des packages Python n√©cessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6a7a1e27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a7a1e27",
        "outputId": "7ccb3668-75ae-434b-e37f-72a4250dc68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.4.8+dfsg-3build1_amd64.deb ...\n",
            "Unpacking zstd (1.4.8+dfsg-3build1) ...\n",
            "Setting up zstd (1.4.8+dfsg-3build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\n",
            "üì¶ Versions install√©es:\n",
            "Version: 0.36.0\n",
            "Version: 4.57.6\n",
            "Version: 1.10.1\n",
            "\n",
            "‚úÖ D√©pendances install√©es.\n"
          ]
        }
      ],
      "source": [
        "# D√©pendances syst√®me\n",
        "!apt-get update -qq\n",
        "! apt-get install -y zstd -qq\n",
        "\n",
        "# D√©pendances Python\n",
        "!python -m pip install -q --upgrade pip\n",
        "!python -m pip install -q marker-pdf[full] langextract google-generativeai pillow\n",
        "\n",
        "# Installer hf_transfer pour des t√©l√©chargements plus rapides (sans casser les d√©pendances)\n",
        "!pip install -q hf_transfer --no-deps\n",
        "\n",
        "# Activer hf_transfer\n",
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "\n",
        "# V√©rifier les versions\n",
        "print(\"\\nüì¶ Versions install√©es:\")\n",
        "!pip show huggingface_hub 2>/dev/null | grep Version\n",
        "! pip show transformers 2>/dev/null | grep Version\n",
        "!pip show marker-pdf 2>/dev/null | grep Version\n",
        "\n",
        "print(\"\\n‚úÖ D√©pendances install√©es.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9950b81",
      "metadata": {
        "id": "e9950b81"
      },
      "source": [
        "## √âtape 3 ‚Äî Configurer les dossiers de travail\n",
        "Modifiez les chemins selon votre Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "749433f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "749433f3",
        "outputId": "e12cafc3-cba0-4ebd-f2bd-2ae020671ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üìÅ CONFIGURATION\n",
            "============================================================\n",
            "üìÇ Entr√©e: /content/drive/MyDrive/G√©opolitique et Souverainet√© Num√©riques/ALL/ALLPDF\n",
            "üìÇ Sortie: /content/drive/MyDrive/G√©opolitique et Souverainet√© Num√©riques/ALL/ALLMD\n",
            "üìÑ PDFs: 54\n",
            "üìÇ Structure par fichier:  <nom_fichier>/\n",
            "   ‚îú‚îÄ‚îÄ _ANALYSES/\n",
            "   ‚îú‚îÄ‚îÄ _FIGURES/\n",
            "   ‚îú‚îÄ‚îÄ _LOGS/\n",
            "   ‚îî‚îÄ‚îÄ _REFERENCES/\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# === MODIFIEZ CES CHEMINS ===\n",
        "INPUT_DIR = Path(\"/content/drive/MyDrive/G√©opolitique et Souverainet√© Num√©riques/ALL/ALLPDF\")\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/G√©opolitique et Souverainet√© Num√©riques/ALL/ALLMD\")\n",
        "\n",
        "assert INPUT_DIR.exists(), f\"‚ùå Dossier introuvable: {INPUT_DIR}\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Dossier global pour les logs du pipeline\n",
        "GLOBAL_LOGS_DIR = OUTPUT_DIR / \"_PIPELINE_LOGS\"\n",
        "GLOBAL_LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def get_doc_folders(doc_name):\n",
        "    \"\"\"Cr√©e et retourne les dossiers pour un document donn√©.\"\"\"\n",
        "    doc_dir = OUTPUT_DIR / doc_name\n",
        "    doc_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    folders = {\n",
        "        \"root\": doc_dir,\n",
        "        \"figures\": doc_dir / \"_FIGURES\",\n",
        "        \"references\": doc_dir / \"_REFERENCES\",\n",
        "        \"analyses\": doc_dir / \"_ANALYSES\",\n",
        "        \"logs\": doc_dir / \"_LOGS\",\n",
        "    }\n",
        "\n",
        "    for folder in folders.values():\n",
        "        folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    return folders\n",
        "\n",
        "pdf_files = sorted([p for p in INPUT_DIR.iterdir() if p.suffix.lower() == \".pdf\"])\n",
        "print(\"=\"*60)\n",
        "print(\"üìÅ CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üìÇ Entr√©e: {INPUT_DIR}\")\n",
        "print(f\"üìÇ Sortie: {OUTPUT_DIR}\")\n",
        "print(f\"üìÑ PDFs: {len(pdf_files)}\")\n",
        "print(f\"üìÇ Structure par fichier:  <nom_fichier>/\")\n",
        "print(f\"   ‚îú‚îÄ‚îÄ _ANALYSES/\")\n",
        "print(f\"   ‚îú‚îÄ‚îÄ _FIGURES/\")\n",
        "print(f\"   ‚îú‚îÄ‚îÄ _LOGS/\")\n",
        "print(f\"   ‚îî‚îÄ‚îÄ _REFERENCES/\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a5c801b",
      "metadata": {
        "id": "8a5c801b"
      },
      "source": [
        "## √âtape 4 ‚Äî Ollama + Gemma 3 4B\n",
        "Installation et d√©marrage de Gemma 3 4B via Ollama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "352143f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "352143f1",
        "outputId": "9c4caa0b-fc5d-4f3d-f2e7-1d37284e1efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installation d'Ollama...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "‚è≥ D√©marrage du serveur Ollama...\n",
            "‚úÖ Serveur Ollama pr√™t!\n",
            "\n",
            "üì• T√©l√©chargement de Gemma 3 4B (‚âà3GB)...\n",
            "   Cela peut prendre plusieurs minutes...\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\n",
            "‚úÖ Gemma 3 4B t√©l√©charg√©!\n",
            "üî• Pr√©chauffage du mod√®le...\n",
            "‚úÖ Gemma 3 4B pr√™t et op√©rationnel!\n",
            "\n",
            "============================================================\n",
            "ü§ñ OLLAMA CONFIGUR√â\n",
            "============================================================\n",
            "Mod√®le: gemma3:4b\n",
            "Serveur: http://localhost:11434\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "USE_OLLAMA = True  # Activ√© par d√©faut pour Gemma local\n",
        "\n",
        "ollama_process = None\n",
        "\n",
        "if USE_OLLAMA:\n",
        "    import subprocess\n",
        "    import time\n",
        "    import os\n",
        "\n",
        "    # Installer requests si n√©cessaire\n",
        "    try:\n",
        "        import requests\n",
        "    except ImportError:\n",
        "        !pip install -q requests\n",
        "        import requests\n",
        "\n",
        "    # Installer Ollama\n",
        "    print(\"üì¶ Installation d'Ollama...\")\n",
        "    !curl -fsSL https://ollama.com/install.sh 2>/dev/null | sh 2>&1 | tail -n 3\n",
        "\n",
        "    # D√©marrer Ollama en arri√®re-plan\n",
        "    ollama_process = subprocess.Popen(\n",
        "        [\"ollama\", \"serve\"],\n",
        "        stdout=subprocess.DEVNULL,\n",
        "        stderr=subprocess.DEVNULL\n",
        "    )\n",
        "    print(\"‚è≥ D√©marrage du serveur Ollama...\")\n",
        "\n",
        "    # Attendre que le serveur soit pr√™t (avec timeout de 30 secondes)\n",
        "    server_ready = False\n",
        "    for i in range(30):\n",
        "        try:\n",
        "            response = requests.get(\"http://localhost:11434/api/tags\", timeout=2)\n",
        "            if response.status_code == 200:\n",
        "                print(\"‚úÖ Serveur Ollama pr√™t!\")\n",
        "                server_ready = True\n",
        "                break\n",
        "        except:\n",
        "            pass\n",
        "        time.sleep(1)\n",
        "\n",
        "    if not server_ready:\n",
        "        print(\"‚ö†Ô∏è Le serveur Ollama n'a pas d√©marr√© √† temps\")\n",
        "        print(\"   Essayez de r√©ex√©cuter cette cellule.\")\n",
        "\n",
        "    # T√©l√©charger Gemma 3 4B (SANS espace dans le nom!)\n",
        "    print(\"\\nüì• T√©l√©chargement de Gemma 3 4B (‚âà3GB)...\")\n",
        "    print(\"   Cela peut prendre plusieurs minutes...\")\n",
        "    !ollama pull gemma3:4b\n",
        "\n",
        "    # V√©rification\n",
        "    result = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
        "    if \"gemma3:4b\" in result.stdout or \"gemma3\" in result.stdout:\n",
        "        print(\"\\n‚úÖ Gemma 3 4B t√©l√©charg√©!\")\n",
        "\n",
        "        # Pr√©chauffer le mod√®le avec une requ√™te test\n",
        "        print(\"üî• Pr√©chauffage du mod√®le...\")\n",
        "        test_result = subprocess.run(\n",
        "            [\"ollama\", \"run\", \"gemma3:4b\", \"R√©ponds uniquement: OK\"],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=30\n",
        "        )\n",
        "\n",
        "        if test_result.returncode == 0:\n",
        "            print(\"‚úÖ Gemma 3 4B pr√™t et op√©rationnel!\")\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"ü§ñ OLLAMA CONFIGUR√â\")\n",
        "            print(\"=\"*60)\n",
        "            print(\"Mod√®le: gemma3:4b\")\n",
        "            print(\"Serveur: http://localhost:11434\")\n",
        "            print(\"=\"*60)\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Avertissement: Le test du mod√®le a √©chou√©\")\n",
        "            print(\"   Le mod√®le devrait quand m√™me fonctionner.\")\n",
        "    else:\n",
        "        print(\"‚ùå Erreur: Gemma 3 4B non trouv√©\")\n",
        "        print(\"Mod√®les disponibles:\")\n",
        "        print(result.stdout if result.stdout else \"Aucun mod√®le\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Ollama d√©sactiv√©. Mettez USE_OLLAMA = True pour l'activer.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ae817d",
      "metadata": {
        "id": "04ae817d"
      },
      "source": [
        "## √âtape 5 ‚Äî Configurer Marker\n",
        "Chargement des mod√®les Marker (~4GB) depuis le cache Drive.\n",
        "\n",
        "**‚ö° Premier lancement:** 10-20 minutes (t√©l√©chargement + sauvegarde sur Drive)\n",
        "\n",
        "**üöÄ Lancements suivants:** 1-2 minutes (chargement depuis Drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ca0f4c3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0f4c3b",
        "outputId": "65415dac-6c19-4a09-8e44-e84604507857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üñ•Ô∏è CONFIGURATION MAT√âRIELLE\n",
            "============================================================\n",
            "Device: cuda\n",
            "GPU: Tesla T4\n",
            "VRAM: 15.8 GB\n",
            "\n",
            "üíæ Cache Drive: 3.53 GB\n",
            "üöÄ Mod√®les trouv√©s en cache! Chargement rapide...\n",
            "============================================================\n",
            "\n",
            "üì¶ Chargement des mod√®les Marker...\n",
            "   ‚ö° Chargement depuis le cache Drive...\n",
            "‚ö†Ô∏è Impossible d'importer OpenAILLMService. Le LLM sera d√©sactiv√© pour Marker.\n",
            "\n",
            "‚öôÔ∏è Cr√©ation du dictionnaire de mod√®les...\n",
            "‚úì Configuration du convertisseur...\n",
            "\n",
            "============================================================\n",
            "‚úÖ MARKER CONFIGUR√â AVEC SUCC√àS!\n",
            "============================================================\n",
            "‚è±Ô∏è Dur√©e: 0.4 minutes\n",
            "üì¶ T√©l√©charg√© cette session: 0.00 GB\n",
            "üíæ Cache total sur Drive: 3.53 GB\n",
            "üñºÔ∏è Extraction d'images: D√©sactiv√©e\n",
            "ü§ñ LLM: D√©sactiv√©\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import shutil\n",
        "import base64\n",
        "import logging\n",
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# === OPTION: EXTRACTION D'IMAGES ===\n",
        "EXTRACT_IMAGES = False  # Mettre True pour extraire les images (peut causer des erreurs avec certains PDFs)\n",
        "\n",
        "# === CONFIGURATION DES LOGS ===\n",
        "# D√©sactiver les warnings non critiques\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Configurer le logging pour r√©duire la verbosit√©\n",
        "logging.getLogger().setLevel(logging.WARNING)\n",
        "\n",
        "# R√©duire drastiquement les logs des biblioth√®ques tierces\n",
        "for logger_name in ['transformers', 'torch', 'PIL', 'urllib3', 'filelock',\n",
        "                     'huggingface_hub', 'marker', 'datasets']:\n",
        "    logging.getLogger(logger_name).setLevel(logging.ERROR)\n",
        "\n",
        "# Variables d'environnement pour r√©duire les logs\n",
        "os.environ['TRANSFORMERS_VERBOSITY'] = 'error'\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '0'  # Garder les barres de progression\n",
        "\n",
        "# S'assurer que le cache Drive est bien configur√©\n",
        "os.environ[\"HF_HOME\"] = str(HF_CACHE_DRIVE)\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = str(HF_CACHE_DRIVE)\n",
        "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = str(HF_CACHE_DRIVE)\n",
        "os.environ[\"TORCH_HOME\"] = str(TORCH_CACHE_DRIVE)\n",
        "# Forcer HF Transfer\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "\n",
        "# === FORCER LE T√âL√âCHARGEMENT DES MOD√àLES SURYA DEPUIS HUGGING FACE ===\n",
        "os.environ[\"SURYA_LAYOUT_MODEL\"] = \"vikp/surya_layout\"\n",
        "os.environ[\"SURYA_REC_MODEL\"] = \"vikp/surya_rec\"\n",
        "os.environ[\"SURYA_DET_MODEL\"] = \"vikp/surya_det\"\n",
        "os.environ[\"SURYA_ORDER_MODEL\"] = \"vikp/surya_order\"\n",
        "os.environ[\"SURYA_TABLE_REC_MODEL\"] = \"vikp/surya_tablerec\"\n",
        "os.environ[\"SURYA_DOWNLOAD_BACKEND\"] = \"huggingface\"\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"=\"*60)\n",
        "print(\"üñ•Ô∏è CONFIGURATION MAT√âRIELLE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# V√©rifier le cache existant\n",
        "def get_dir_size(path):\n",
        "    total = 0\n",
        "    if path.exists():\n",
        "        for f in path.rglob(\"*\"):\n",
        "            if f.is_file():\n",
        "                try:\n",
        "                    total += f.stat().st_size\n",
        "                except:\n",
        "                    pass\n",
        "    return total / 1e9\n",
        "\n",
        "initial_cache_size = get_dir_size(DRIVE_CACHE_DIR)\n",
        "print(f\"\\nüíæ Cache Drive: {initial_cache_size:.2f} GB\")\n",
        "\n",
        "if initial_cache_size > 3:\n",
        "    print(\"üöÄ Mod√®les trouv√©s en cache! Chargement rapide...\")\n",
        "else:\n",
        "    print(\"üì• Premier t√©l√©chargement des mod√®les Marker (~4GB)\")\n",
        "    print(\"   ‚è±Ô∏è Dur√©e estim√©e: 10-20 minutes\")\n",
        "    print(\"   üíæ Les mod√®les seront sauvegard√©s sur Drive\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Chronom√®tre\n",
        "start_time = time.time()\n",
        "\n",
        "# Charger les mod√®les avec messages de progression\n",
        "print(\"\\nüì¶ Chargement des mod√®les Marker...\")\n",
        "if initial_cache_size > 3:\n",
        "    print(\"   ‚ö° Chargement depuis le cache Drive...\")\n",
        "else:\n",
        "    print(\"   üì• T√©l√©chargement en cours...\")\n",
        "\n",
        "from marker.converters.pdf import PdfConverter\n",
        "from marker.models import create_model_dict\n",
        "from marker.config.parser import ConfigParser\n",
        "\n",
        "# Tenter d'importer le service LLM appropri√©\n",
        "# On utilise OpenAILLMService pour communiquer avec Ollama\n",
        "LLM_SERVICE_CLS = None\n",
        "# NOTE: USE_OLLAMA is read from the global scope here. Ensure it's True if you want LLM with Marker.\n",
        "# Forcing USE_OLLAMA = True here to align with user's likely intent if Ollama is installed.\n",
        "USE_OLLAMA = True # Explicitly set to True here for Marker config\n",
        "\n",
        "if USE_OLLAMA:\n",
        "    try:\n",
        "        # Try the most common path first\n",
        "        from marker.llm.openai import OpenAILLMService\n",
        "        LLM_SERVICE_CLS = OpenAILLMService\n",
        "        print(\"‚úÖ Service LLM: OpenAILLMService (compatible Ollama)\")\n",
        "    except ImportError:\n",
        "        try:\n",
        "            # Fallback tentative autre chemin (if Marker has a different structure)\n",
        "            from marker.services.openai import OpenAILLMService\n",
        "            LLM_SERVICE_CLS = OpenAILLMService\n",
        "            print(\"‚úÖ Service LLM: OpenAILLMService (via path alternatif)\")\n",
        "        except ImportError:\n",
        "            print(\"‚ö†Ô∏è Impossible d'importer OpenAILLMService. Le LLM sera d√©sactiv√© pour Marker.\")\n",
        "            USE_OLLAMA = False # Revert if import fails\n",
        "\n",
        "# Configuration pour Ollama via API OpenAI\n",
        "if USE_OLLAMA:\n",
        "    os.environ[\"MARKER_LLM_PROVIDER\"] = \"openai\"\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"http://localhost:11434/v1\"\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"ollama\"\n",
        "    os.environ[\"OPENAI_MODEL\"] = \"gemma3:4b\"\n",
        "\n",
        "# Configuration Marker\n",
        "marker_config = {\n",
        "    \"workers\": 2,\n",
        "    \"extract_images\": EXTRACT_IMAGES,\n",
        "    \"images_as_base64\": False,\n",
        "    \"use_llm\": USE_OLLAMA,\n",
        "    \"llm_provider\": \"openai\" if USE_OLLAMA else None,\n",
        "    \"llm_model\": \"gemma3:4b\" if USE_OLLAMA else None,\n",
        "    \"force_ocr\": False,\n",
        "    \"languages\": [\"fr\", \"en\"],\n",
        "    \"paginate_output\": True,\n",
        "    \"batch_size\": 4 if device == \"cuda\" else 2,\n",
        "}\n",
        "\n",
        "print(\"\\n‚öôÔ∏è Cr√©ation du dictionnaire de mod√®les...\")\n",
        "model_dict = create_model_dict()\n",
        "\n",
        "print(\"‚úì Configuration du convertisseur...\")\n",
        "config_parser = ConfigParser(marker_config)\n",
        "\n",
        "# Instanciation avec le service LLM explicite si disponible\n",
        "# Relying on environment variables set above (MARKER_LLM_PROVIDER, OPENAI_BASE_URL, etc.)\n",
        "# for Marker to pick up Ollama LLM config if USE_OLLAMA is True in marker_config.\n",
        "# Removed explicit llm_service argument here to avoid ImportError blocking other settings.\n",
        "converter = PdfConverter(\n",
        "    config=config_parser.generate_config_dict(),\n",
        "    artifact_dict=model_dict\n",
        ")\n",
        "\n",
        "# R√©sum√©\n",
        "elapsed = time.time() - start_time\n",
        "final_cache_size = get_dir_size(DRIVE_CACHE_DIR)\n",
        "downloaded = final_cache_size - initial_cache_size\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ MARKER CONFIGUR√â AVEC SUCC√àS!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"‚è±Ô∏è Dur√©e: {elapsed/60:.1f} minutes\")\n",
        "print(f\"üì¶ T√©l√©charg√© cette session: {max(0, downloaded):.2f} GB\")\n",
        "print(f\"üíæ Cache total sur Drive: {final_cache_size:.2f} GB\")\n",
        "print(f\"üñºÔ∏è Extraction d'images: {'Activ√©e' if EXTRACT_IMAGES else 'D√©sactiv√©e'}\")\n",
        "if USE_OLLAMA:\n",
        "    print(f\"ü§ñ LLM: Gemma 3 4B via Ollama (interface OpenAI)\")\n",
        "else:\n",
        "    print(\"ü§ñ LLM: D√©sactiv√©\")\n",
        "print(\"=\"*60)\n",
        "if downloaded > 0.5:\n",
        "    print(\"\\nüí° Les mod√®les sont maintenant en cache sur votre Drive.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0fc302",
      "metadata": {
        "id": "dd0fc302"
      },
      "source": [
        "## √âtape 6 ‚Äî Fonctions utilitaires\n",
        "Extraction des r√©f√©rences, figures et conversion PDF ‚Üí Markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e5a23cbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5a23cbb",
        "outputId": "5bfbe08f-29e4-4e54-96aa-6cde13e03460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fonctions utilitaires d√©finies. \n"
          ]
        }
      ],
      "source": [
        "def extract_references_from_markdown(markdown_text):\n",
        "    \"\"\"Extrait la section r√©f√©rences/bibliographie du Markdown.\"\"\"\n",
        "    references = {\n",
        "        \"references_text\": \"\",\n",
        "        \"references_list\": [],\n",
        "        \"reference_count\": 0,\n",
        "    }\n",
        "\n",
        "    ref_patterns = [\n",
        "        r\"(?i)(?:^|\\n)#{1,3}\\s*(references|r√©f√©rences|bibliography|bibliographie|works\\s*cited|sources?)\\s*[\\s: ]*\\n([\\s\\S]*?)(?=\\n#{1,3}\\s|\\Z)\",\n",
        "        r\"(?i)(?:^|\\n)\\*\\*(references|r√©f√©rences|bibliography|bibliographie)\\*\\*\\s*[\\s: ]*\\n([\\s\\S]*?)(?=\\n\\*\\*|\\n#{1,3}|\\Z)\",\n",
        "    ]\n",
        "\n",
        "    for pattern in ref_patterns:\n",
        "        match = re.search(pattern, markdown_text, re.MULTILINE)\n",
        "        if match:\n",
        "            ref_section = match.group(2).strip()\n",
        "            references[\"references_text\"] = ref_section\n",
        "\n",
        "            ref_lines = []\n",
        "            lines = ref_section.split(\"\\n\")\n",
        "            current_ref = \"\"\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    if current_ref:\n",
        "                        ref_lines.append(current_ref. strip())\n",
        "                        current_ref = \"\"\n",
        "                    continue\n",
        "\n",
        "                if re.match(r\"^(\\[\\d+\\]|\\d+\\.|[-‚Ä¢]|\\([A-Z])\", line):\n",
        "                    if current_ref:\n",
        "                        ref_lines.append(current_ref.strip())\n",
        "                    current_ref = line\n",
        "                else:\n",
        "                    current_ref += \" \" + line\n",
        "\n",
        "            if current_ref:\n",
        "                ref_lines. append(current_ref.strip())\n",
        "\n",
        "            references[\"references_list\"] = [r for r in ref_lines if len(r) > 20]\n",
        "            references[\"reference_count\"] = len(references[\"references_list\"])\n",
        "            break\n",
        "\n",
        "    return references\n",
        "\n",
        "\n",
        "def extract_figures_info(markdown_text, images_dict):\n",
        "    \"\"\"Extrait les informations sur les figures du document.\"\"\"\n",
        "    figures = []\n",
        "    fig_pattern = r\"(?i)(figure|fig\\.)\\s*(\\d+)?\\s*[:]? \\s*(. {0,120})\"\n",
        "\n",
        "    for match in re.finditer(fig_pattern, markdown_text):\n",
        "        title = (match.group(3) or \"\").strip()\n",
        "        figures.append({\n",
        "            \"label\": match.group(0).strip(),\n",
        "            \"title\": title,\n",
        "        })\n",
        "\n",
        "    if images_dict:\n",
        "        for img_name in images_dict. keys():\n",
        "            existing = any(f.get(\"path\") == img_name for f in figures)\n",
        "            if not existing:\n",
        "                figures.append({\n",
        "                    \"label\": str(img_name),\n",
        "                    \"title\": \"\",\n",
        "                    \"path\": str(img_name),\n",
        "                })\n",
        "\n",
        "    return figures\n",
        "\n",
        "\n",
        "def save_figures(images_dict, doc_folders):\n",
        "    \"\"\"Sauvegarde les figures extraites dans le dossier _FIGURES du document.\"\"\"\n",
        "    if not images_dict:\n",
        "        return []\n",
        "\n",
        "    figures_folder = doc_folders[\"figures\"]\n",
        "    saved_paths = []\n",
        "    used_names = set()  # Pour √©viter les collisions de noms\n",
        "\n",
        "    for idx, (img_name, img_data) in enumerate(images_dict.items(), 1):\n",
        "        # Nettoyer le nom du fichier en retirant tous les caract√®res probl√©matiques\n",
        "        safe_name = re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", str(img_name))\n",
        "        # Supprimer les underscores multiples et en d√©but/fin\n",
        "        safe_name = re.sub(r\"_+\", \"_\", safe_name).strip(\"_\")\n",
        "        # Limiter la longueur du nom (max 100 caract√®res)\n",
        "        safe_name = safe_name[:100]\n",
        "        # Si le nom est vide apr√®s nettoyage, utiliser un index\n",
        "        if not safe_name or len(safe_name) < 3:\n",
        "            safe_name = f\"figure_{idx:03d}\"\n",
        "\n",
        "        # G√©rer les collisions de noms\n",
        "        base_name = safe_name\n",
        "        counter = 1\n",
        "        while safe_name in used_names:\n",
        "            safe_name = f\"{base_name}_{counter}\"\n",
        "            counter += 1\n",
        "        used_names.add(safe_name)\n",
        "\n",
        "        img_path = figures_folder / f\"{safe_name}.png\"\n",
        "\n",
        "        try:\n",
        "            if isinstance(img_data, Image.Image):\n",
        "                # Convertir en RGB si n√©cessaire (pour les images RGBA/P)\n",
        "                if img_data.mode in ('RGBA', 'LA', 'P'):\n",
        "                    rgb_image = Image.new('RGB', img_data.size, (255, 255, 255))\n",
        "                    if img_data.mode == 'P':\n",
        "                        img_data = img_data.convert('RGBA')\n",
        "                    rgb_image.paste(img_data, mask=img_data.split()[-1] if img_data.mode in ('RGBA', 'LA') else None)\n",
        "                    img_data = rgb_image\n",
        "                img_data.save(img_path, \"PNG\", optimize=True)\n",
        "            elif isinstance(img_data, (bytes, bytearray)):\n",
        "                # Sauvegarder directement les bytes\n",
        "                with open(img_path, \"wb\") as f:\n",
        "                    f.write(img_data)\n",
        "            elif isinstance(img_data, str):\n",
        "                if img_data.startswith(\"data:image\"):\n",
        "                    # Donn√©es base64 encod√©es\n",
        "                    b64_data = img_data.split(\",\", 1)[1] if \",\" in img_data else img_data\n",
        "                    with open(img_path, \"wb\") as f:\n",
        "                        f.write(base64.b64decode(b64_data))\n",
        "                elif Path(img_data).exists():\n",
        "                    # Copie depuis un fichier existant\n",
        "                    shutil.copy(img_data, img_path)\n",
        "                else:\n",
        "                    # Tenter de d√©coder comme base64\n",
        "                    try:\n",
        "                        with open(img_path, \"wb\") as f:\n",
        "                            f.write(base64.b64decode(img_data))\n",
        "                    except:\n",
        "                        continue\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            saved_paths.append(str(img_path))\n",
        "        except Exception as e:\n",
        "            # Log l'erreur mais continue le traitement\n",
        "            print(f\"   ‚ö†Ô∏è Impossible de sauvegarder {safe_name}: {str(e)[:80]}\")\n",
        "            continue\n",
        "\n",
        "    return saved_paths\n",
        "\n",
        "\n",
        "def convert_pdf_complete(pdf_path, doc_name):\n",
        "    \"\"\"Conversion compl√®te d'un PDF avec extraction figures et r√©f√©rences.\"\"\"\n",
        "    doc_folders = get_doc_folders(doc_name)\n",
        "\n",
        "    result_data = {\n",
        "        \"doc_name\": doc_name,\n",
        "        \"doc_folder\": str(doc_folders[\"root\"]),\n",
        "        \"markdown_path\": \"\",\n",
        "        \"figures\": [],\n",
        "        \"figures_paths\": [],\n",
        "        \"references\": {},\n",
        "        \"error\": None,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        print(f\"   DEBUG: Tentative de conversion initiale pour {pdf_path.name}...\")\n",
        "        # Conversion Marker avec gestion d'erreur robuste\n",
        "        try:\n",
        "            result = converter(str(pdf_path))\n",
        "            print(\"   DEBUG: Premi√®re conversion r√©ussie.\")\n",
        "        except Exception as conv_error:\n",
        "            import traceback # Ensure traceback is available\n",
        "            print(f\"   DEBUG: Erreur captur√©e dans premi√®re tentative: {conv_error}\")\n",
        "            traceback.print_exc() # Print full traceback here\n",
        "\n",
        "            # If the error concerns images or is of type \"unknown extension\", try without image extraction\n",
        "            if \"extension\" in str(conv_error).lower() or \"image\" in str(conv_error).lower() or \"unknown extension\" in str(conv_error).lower():\n",
        "                print(f\"   ‚ö†Ô∏è Erreur d'extraction d'images (premi√®re tentative): {str(conv_error)[:60]}\")\n",
        "                print(\"   üîÑ Nouvelle tentative SANS extraction d'images...\")\n",
        "\n",
        "                # Reconfigure temporarily Marker without image extraction\n",
        "                from marker.config.parser import ConfigParser\n",
        "                temp_config = {\n",
        "                    \"workers\": 2,\n",
        "                    \"extract_images\": False,  # Disable image extraction\n",
        "                    \"images_as_base64\": False,\n",
        "                    \"use_llm\": False, # LLM disabled for fallback attempt\n",
        "                    \"force_ocr\": False,\n",
        "                    \"languages\": [\"fr\", \"en\"],\n",
        "                    \"paginate_output\": True,\n",
        "                    \"batch_size\": 4 if device == \"cuda\" else 2,\n",
        "                }\n",
        "                config_parser = ConfigParser(temp_config)\n",
        "                from marker.converters.pdf import PdfConverter\n",
        "                temp_converter = PdfConverter(\n",
        "                    config=config_parser.generate_config_dict(),\n",
        "                    artifact_dict=model_dict,\n",
        "                    llm_service=None # Ensure no LLM service for this fallback\n",
        "                )\n",
        "                try:\n",
        "                    result = temp_converter(str(pdf_path))\n",
        "                    print(f\"   DEBUG: Nouvelle tentative r√©ussie sans extraction d'images.\")\n",
        "                except Exception as second_conv_error:\n",
        "                    print(f\"   ‚ùå Erreur (seconde tentative sans images): {second_conv_error}\")\n",
        "                    traceback.print_exc() # Print full traceback here for second attempt\n",
        "                    raise second_conv_error # Relaunch the error if the second attempt also fails\n",
        "            else:\n",
        "                raise # Relaunch the error if it's not an image/extension issue\n",
        "\n",
        "        markdown_text = getattr(result, \"markdown\", \"\") or \"\"\n",
        "        images_dict = getattr(result, \"images\", {}) or {}\n",
        "\n",
        "        # Nettoyer le dictionnaire d'images pour enlever les entr√©es invalides\n",
        "        cleaned_images = {}\n",
        "        if images_dict:\n",
        "            for key, value in images_dict.items():\n",
        "                # Ignorer les cl√©s ou valeurs None/vides\n",
        "                if key and value is not None:\n",
        "                    # V√©rifier que la cl√© ne contient pas de caract√®res probl√©matiques\n",
        "                    if not any(char in str(key) for char in ['?', '*', '<', '>', '|', '\\x00']):\n",
        "                        cleaned_images[key] = value\n",
        "                    else:\n",
        "                        print(f\"   ‚ö†Ô∏è Image ignor√©e (nom invalide): {str(key)[:30]}\")\n",
        "\n",
        "        images_dict = cleaned_images\n",
        "\n",
        "        md_path = doc_folders[\"root\"] / f\"{doc_name}.md\"\n",
        "        with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(markdown_text)\n",
        "\n",
        "        result_data[\"markdown_path\"] = str(md_path)\n",
        "        result_data[\"figures_paths\"] = save_figures(images_dict, doc_folders)\n",
        "        result_data[\"figures\"] = extract_figures_info(markdown_text, images_dict)\n",
        "\n",
        "        result_data[\"references\"] = extract_references_from_markdown(markdown_text)\n",
        "        if result_data[\"references\"].get(\"reference_count\", 0) > 0:\n",
        "            ref_path = doc_folders[\"references\"] / f\"{doc_name}_references.json\"\n",
        "            with open(ref_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(result_data[\"references\"], f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        return result_data\n",
        "    except Exception as e:\n",
        "        import traceback # Ensure traceback is imported\n",
        "        print(f\"   DEBUG: Capture d'erreur g√©n√©rique dans convert_pdf_complete: {e}\")\n",
        "        traceback.print_exc() # Print the full traceback for outer catch\n",
        "        result_data[\"error\"] = str(e)\n",
        "        error_log = doc_folders[\"logs\"] / \"error.txt\"\n",
        "        with open(error_log, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Erreur: {str(e)}\\nTraceback:\\n{traceback.format_exc()}\\nDate: {datetime.now().isoformat()}\")\n",
        "        return result_data\n",
        "\n",
        "print(\"‚úÖ Fonctions utilitaires d√©finies. \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f235df66",
      "metadata": {
        "id": "f235df66"
      },
      "source": [
        "## √âtape 7 ‚Äî LangExtract\n",
        "Extraction structur√©e avec LangExtract (activ√© par d√©faut avec Ollama)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4261fafe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4261fafe",
        "outputId": "eda7642b-8178-449d-9149-47e9b364f935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ollama d√©tect√© - Utilisation de Gemma 3 4B\n",
            "‚úÖ LangExtract configur√© (Provider: ollama, Model: gemma3:4b)\n"
          ]
        }
      ],
      "source": [
        "USE_LANGEXTRACT = True\n",
        "\n",
        "# V√©rifier si Ollama est disponible (ind√©pendamment de la config Marker)\n",
        "OLLAMA_AVAILABLE = False\n",
        "try:\n",
        "    import requests\n",
        "    response = requests.get(\"http://localhost:11434/api/tags\", timeout=2)\n",
        "    if response.status_code == 200:\n",
        "        OLLAMA_AVAILABLE = True\n",
        "        print(\"‚úÖ Ollama d√©tect√© - Utilisation de Gemma 3 4B\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Ollama non disponible - Utilisation de OpenAI requis\")\n",
        "\n",
        "LANGEXTRACT_CONFIG = {\n",
        "    \"provider\": \"ollama\" if OLLAMA_AVAILABLE else \"openai\",\n",
        "    \"model\": \"gemma3:4b\" if OLLAMA_AVAILABLE else \"gpt-3.5-turbo\",\n",
        "    \"base_url\": \"http://localhost:11434\" if OLLAMA_AVAILABLE else None,\n",
        "}\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"Vous √™tes un assistant d'analyse pour des documents en sciences sociales.\n",
        "Retournez un JSON structur√© avec les sections suivantes:\n",
        "\n",
        "1.  CONTEXTE\n",
        "- Th√®me principal\n",
        "- Zone g√©ographique\n",
        "- P√©riode\n",
        "\n",
        "2. ACTEURS\n",
        "- Institutions\n",
        "- Pays\n",
        "- Organisations\n",
        "\n",
        "3. CONCEPTS CL√âS\n",
        "- Mots-cl√©s\n",
        "- Concepts\n",
        "\n",
        "4. DONN√âES\n",
        "- Chiffres cl√©s (si disponibles)\n",
        "\n",
        "5. R√âF√âRENCES\n",
        "- Principales r√©f√©rences cit√©es\n",
        "\n",
        "6. FIGURES ET TABLEAUX\n",
        "- Liste des figures mentionn√©es\n",
        "\n",
        "R√©pondez uniquement avec un JSON valide.\"\"\"\n",
        "\n",
        "def _safe_json(obj):\n",
        "    try:\n",
        "        return json.loads(json.dumps(obj))\n",
        "    except Exception:\n",
        "        return {\"raw\": str(obj)}\n",
        "\n",
        "\n",
        "def extract_with_langextract(markdown_text, doc_name, doc_folders, references_data=None, figures_data=None):\n",
        "    \"\"\"Extraction structur√©e avec LangExtract.\"\"\"\n",
        "    if not USE_LANGEXTRACT:\n",
        "        return {\"status\": \"skipped\", \"reason\": \"USE_LANGEXTRACT=False\"}\n",
        "\n",
        "    enriched_text = markdown_text\n",
        "\n",
        "    if references_data and references_data.get(\"reference_count\", 0) > 0:\n",
        "        enriched_text += \"\\n\\n## R√âF√âRENCES\\n\"\n",
        "        enriched_text += f\"Nombre de r√©f√©rences: {references_data['reference_count']}\\n\"\n",
        "        for i, ref in enumerate(references_data. get(\"references_list\", [])[:20], 1):\n",
        "            enriched_text += f\"[{i}] {ref}\\n\"\n",
        "\n",
        "    if figures_data:\n",
        "        enriched_text += \"\\n\\n## FIGURES IDENTIFI√âES\\n\"\n",
        "        enriched_text += f\"Nombre de figures:  {len(figures_data)}\\n\"\n",
        "        for fig in figures_data[: 10]:\n",
        "            enriched_text += f\"- {fig. get('label', '')} {fig.get('title', '')}\\n\"\n",
        "\n",
        "    try:\n",
        "        import langextract as lx\n",
        "\n",
        "        extractor_kwargs = {\n",
        "            \"prompt\": PROMPT_TEMPLATE,\n",
        "        }\n",
        "\n",
        "        if OLLAMA_AVAILABLE and LANGEXTRACT_CONFIG[\"base_url\"]:\n",
        "            extractor_kwargs[\"provider\"] = \"ollama\"\n",
        "            extractor_kwargs[\"model\"] = LANGEXTRACT_CONFIG[\"model\"]\n",
        "            extractor_kwargs[\"base_url\"] = LANGEXTRACT_CONFIG[\"base_url\"]\n",
        "\n",
        "        if hasattr(lx, \"extract\"):\n",
        "            extraction = lx.extract(enriched_text, **extractor_kwargs)\n",
        "        elif hasattr(lx, \"LangExtract\"):\n",
        "            extractor = lx.LangExtract(**extractor_kwargs)\n",
        "            extraction = extractor. extract(enriched_text)\n",
        "        else:\n",
        "            return {\"status\": \"error\", \"error\": \"API LangExtract introuvable\"}\n",
        "\n",
        "        result = _safe_json(extraction)\n",
        "\n",
        "        extraction_path = doc_folders[\"analyses\"] / f\"{doc_name}_langextract.json\"\n",
        "        with open(extraction_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return {\"status\":  \"error\", \"error\":  str(e)}\n",
        "\n",
        "print(f\"‚úÖ LangExtract configur√© (Provider: {LANGEXTRACT_CONFIG['provider']}, Model: {LANGEXTRACT_CONFIG['model']})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "216e2839",
      "metadata": {
        "id": "216e2839"
      },
      "source": [
        "## √âtape 8 ‚Äî Test sur un PDF (optionnel)\n",
        "Permet de valider la configuration avant le batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b4b595a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4b595a6",
        "outputId": "4fb45cdd-5553-4a12-a854-216bd156f193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Test sur:  Against Sovereignty in Cyberspace.pdf\n",
            "‚è≥ Conversion en cours...\n",
            "\n",
            "   DEBUG: Tentative de conversion initiale pour Against Sovereignty in Cyberspace.pdf...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recognizing Layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:12<00:00,  1.82it/s]\n",
            "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 22.53it/s]\n",
            "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.59it/s]\n",
            "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [01:19<00:00,  1.95s/it]\n",
            "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.93it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   DEBUG: Premi√®re conversion r√©ussie.\n",
            "‚úÖ Conversion r√©ussie en 104.1s! \n",
            "   üìÇ Dossier: /content/drive/MyDrive/G√©opolitique et Souverainet√© Num√©riques/ALL/ALLMD/Against Sovereignty in Cyberspace\n",
            "   üìÑ Markdown: /content/drive/MyDrive/G√©opolitique et Souverainet√© Num√©riques/ALL/ALLMD/Against Sovereignty in Cyberspace/Against Sovereignty in Cyberspace.md\n",
            "   üñºÔ∏è Figures: 0\n",
            "   üìö R√©f√©rences: 0\n"
          ]
        }
      ],
      "source": [
        "pdf_files = sorted([p for p in INPUT_DIR.iterdir() if p.suffix.lower() == \".pdf\"])\n",
        "\n",
        "if pdf_files:\n",
        "    sample_path = pdf_files[0]\n",
        "    sample_name = sample_path.stem\n",
        "    print(f\"üß™ Test sur:  {sample_path.name}\")\n",
        "    print(\"‚è≥ Conversion en cours...\\n\")\n",
        "\n",
        "    test_start = time.time()\n",
        "    sample_result = convert_pdf_complete(sample_path, sample_name)\n",
        "    test_elapsed = time.time() - test_start\n",
        "\n",
        "    if sample_result.get(\"error\"):\n",
        "        print(f\"‚ùå Erreur:  {sample_result['error']}\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Conversion r√©ussie en {test_elapsed:.1f}s! \")\n",
        "        print(f\"   üìÇ Dossier: {sample_result['doc_folder']}\")\n",
        "        print(f\"   üìÑ Markdown: {sample_result['markdown_path']}\")\n",
        "        print(f\"   üñºÔ∏è Figures: {len(sample_result['figures_paths'])}\")\n",
        "        print(f\"   üìö R√©f√©rences: {sample_result['references'].get('reference_count', 0)}\")\n",
        "else:\n",
        "    print(\"‚ùå Aucun PDF trouv√© dans le dossier d'entr√©e.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e110727a",
      "metadata": {
        "id": "e110727a"
      },
      "source": [
        "## √âtape 9 ‚Äî Pipeline complet avec reprise\n",
        "Traitement batch + logs + reprise automatique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc4b352",
      "metadata": {
        "id": "acc4b352"
      },
      "outputs": [],
      "source": [
        "import time as time_module\n",
        "\n",
        "def process_all_documents():\n",
        "    \"\"\"Traite tous les documents PDF avec reprise automatique.\"\"\"\n",
        "\n",
        "    all_pdfs = sorted([p for p in INPUT_DIR.iterdir() if p.suffix.lower() == \".pdf\"])\n",
        "\n",
        "    if not all_pdfs:\n",
        "        print(\"‚ùå Aucun PDF trouv√© dans le dossier d'entr√©e! \")\n",
        "        print(f\"   Chemin v√©rifi√©: {INPUT_DIR}\")\n",
        "        return [], []\n",
        "\n",
        "    log_file = GLOBAL_LOGS_DIR / f\"processing_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "    progress_file = GLOBAL_LOGS_DIR / \"progress.json\"\n",
        "\n",
        "    def log_message(message):\n",
        "        print(message)\n",
        "        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(message + \"\\n\")\n",
        "\n",
        "    processed_files = set()\n",
        "    if progress_file.exists():\n",
        "        try:\n",
        "            with open(progress_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                progress_data = json.load(f)\n",
        "                processed_files = set(progress_data.get(\"processed\", []))\n",
        "            log_message(f\"üìÇ Reprise:  {len(processed_files)} fichiers d√©j√† trait√©s\")\n",
        "        except Exception:\n",
        "            processed_files = set()\n",
        "\n",
        "    remaining_pdfs = [p for p in all_pdfs if p. name not in processed_files]\n",
        "\n",
        "    log_message(\"=\"*60)\n",
        "    log_message(f\"üìÑ Total PDFs: {len(all_pdfs)}\")\n",
        "    log_message(f\"‚úÖ D√©j√† trait√©s: {len(processed_files)}\")\n",
        "    log_message(f\"‚è≥ Restants: {len(remaining_pdfs)}\")\n",
        "    log_message(\"=\"*60)\n",
        "\n",
        "    if not remaining_pdfs:\n",
        "        log_message(\"‚úÖ Tous les fichiers ont d√©j√† √©t√© trait√©s!\")\n",
        "        return [], []\n",
        "\n",
        "    results = []\n",
        "    errors = []\n",
        "    start_time = time_module.time()\n",
        "\n",
        "    def save_progress():\n",
        "        with open(progress_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({\n",
        "                \"processed\": list(processed_files),\n",
        "                \"last_update\": datetime.now().isoformat()\n",
        "            }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    for idx, pdf_path in enumerate(remaining_pdfs, 1):\n",
        "        doc_name = pdf_path.stem\n",
        "        doc_start_time = time_module.time()\n",
        "\n",
        "        log_message(f\"\\n[{idx}/{len(remaining_pdfs)}] üöÄ Traitement:  {pdf_path.name}\")\n",
        "\n",
        "        conversion_result = convert_pdf_complete(pdf_path, doc_name)\n",
        "\n",
        "        if conversion_result.get(\"error\"):\n",
        "            errors. append({\"file\": pdf_path. name, \"error\": conversion_result[\"error\"]})\n",
        "            log_message(f\"   ‚ùå Erreur conversion: {conversion_result['error']}\")\n",
        "            processed_files.add(pdf_path.name)\n",
        "            save_progress()\n",
        "            continue\n",
        "\n",
        "        doc_folders = get_doc_folders(doc_name)\n",
        "\n",
        "        log_message(\n",
        "            f\"   üñºÔ∏è Figures: {len(conversion_result['figures'])} trouv√©es, \"\n",
        "            f\"{len(conversion_result['figures_paths'])} sauvegard√©es\"\n",
        "        )\n",
        "        log_message(\n",
        "            f\"   üìö R√©f√©rences: {conversion_result['references'].get('reference_count', 0)} extraites\"\n",
        "        )\n",
        "\n",
        "        extraction = None\n",
        "        if USE_LANGEXTRACT:\n",
        "            log_message(\"   üîç Extraction LangExtract... \")\n",
        "            with open(conversion_result['markdown_path'], 'r', encoding='utf-8') as f:\n",
        "                md_content = f.read()\n",
        "            extraction = extract_with_langextract(\n",
        "                md_content,\n",
        "                doc_name,\n",
        "                doc_folders,\n",
        "                conversion_result['references'],\n",
        "                conversion_result['figures'],\n",
        "            )\n",
        "            if extraction. get(\"status\") == \"error\":\n",
        "                log_message(f\"   ‚ö†Ô∏è LangExtract: {extraction. get('error', 'Erreur inconnue')}\")\n",
        "            else:\n",
        "                log_message(\"   ‚úÖ LangExtract termin√©\")\n",
        "\n",
        "        analysis = {\n",
        "            \"doc_name\": doc_name,\n",
        "            \"source_pdf\": str(pdf_path),\n",
        "            \"doc_folder\": str(doc_folders[\"root\"]),\n",
        "            \"processed_at\": datetime.now().isoformat(),\n",
        "            \"processing_time_seconds\": round(time_module.time() - doc_start_time, 2),\n",
        "            \"conversion\": {\n",
        "                \"markdown_path\": conversion_result['markdown_path'],\n",
        "                \"figures_count\": len(conversion_result['figures']),\n",
        "                \"figures_saved\": len(conversion_result['figures_paths']),\n",
        "                \"figures_paths\": conversion_result['figures_paths'],\n",
        "                \"references_count\": conversion_result['references'].get('reference_count', 0),\n",
        "            },\n",
        "            \"references\": conversion_result['references'],\n",
        "            \"figures\": conversion_result['figures'],\n",
        "            \"langextract\": extraction,\n",
        "        }\n",
        "\n",
        "        analysis_path = doc_folders[\"analyses\"] / f\"{doc_name}_analysis.json\"\n",
        "        with open(analysis_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(analysis, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        doc_log_path = doc_folders[\"logs\"] / \"processing. log\"\n",
        "        with open(doc_log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f. write(f\"Trait√© le: {datetime.now().isoformat()}\\n\")\n",
        "            f.write(f\"Dur√©e: {analysis['processing_time_seconds']} secondes\\n\")\n",
        "            f.write(f\"Figures:  {len(conversion_result['figures_paths'])}\\n\")\n",
        "            f.write(f\"R√©f√©rences: {conversion_result['references'].get('reference_count', 0)}\\n\")\n",
        "\n",
        "        results.append(analysis)\n",
        "        processed_files.add(pdf_path.name)\n",
        "        save_progress()\n",
        "\n",
        "        elapsed = time_module.time() - doc_start_time\n",
        "        log_message(f\"   ‚è±Ô∏è Dur√©e: {elapsed:.1f}s\")\n",
        "\n",
        "    total_time = time_module.time() - start_time\n",
        "    log_message(\"\\n\" + \"=\"*60)\n",
        "    log_message(f\"‚úÖ Traitement termin√© en {total_time:.1f} secondes\")\n",
        "    log_message(f\"   üìÑ R√©ussis: {len(results)}\")\n",
        "    log_message(f\"   ‚ùå Erreurs: {len(errors)}\")\n",
        "    log_message(\"=\"*60)\n",
        "\n",
        "    return results, errors\n",
        "\n",
        "\n",
        "def export_all_results(results):\n",
        "    \"\"\"Exporte les r√©sultats globaux.\"\"\"\n",
        "    if not results:\n",
        "        print(\"‚ÑπÔ∏è Aucun r√©sultat √† exporter. \")\n",
        "        return\n",
        "\n",
        "    summary_path = GLOBAL_LOGS_DIR / \"_SUMMARY.json\"\n",
        "    report_md_path = GLOBAL_LOGS_DIR / \"_REPORT. md\"\n",
        "\n",
        "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    all_references = []\n",
        "    for data in results:\n",
        "        refs = data.get(\"references\", {})\n",
        "        if refs. get(\"references_list\"):\n",
        "            for ref in refs[\"references_list\"]:\n",
        "                all_references.append({\n",
        "                    \"document\": data. get(\"doc_name\", \"\"),\n",
        "                    \"reference\": ref,\n",
        "                })\n",
        "\n",
        "    if all_references:\n",
        "        biblio_path = GLOBAL_LOGS_DIR / \"_BIBLIOGRAPHIE_COMPLETE.json\"\n",
        "        with open(biblio_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json. dump(all_references, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"üìö Bibliographie:  {biblio_path} ({len(all_references)} r√©f√©rences)\")\n",
        "\n",
        "    all_figures = []\n",
        "    for data in results:\n",
        "        for fig_path in data.get(\"conversion\", {}).get(\"figures_paths\", []):\n",
        "            all_figures.append({\n",
        "                \"document\": data. get(\"doc_name\", \"\"),\n",
        "                \"path\": fig_path,\n",
        "            })\n",
        "\n",
        "    if all_figures:\n",
        "        figures_index_path = GLOBAL_LOGS_DIR / \"_INDEX_FIGURES.json\"\n",
        "        with open(figures_index_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(all_figures, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"üñºÔ∏è Index figures: {figures_index_path} ({len(all_figures)} figures)\")\n",
        "\n",
        "    md_lines = []\n",
        "    md_lines.append(\"# Rapport de traitement MFEGSN\\n\\n\")\n",
        "    md_lines.append(f\"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
        "    md_lines.append(f\"- **Total documents trait√©s:** {len(results)}\\n\")\n",
        "    md_lines.append(f\"- **Total figures extraites:** {len(all_figures)}\\n\")\n",
        "    md_lines.append(f\"- **Total r√©f√©rences:** {len(all_references)}\\n\\n\")\n",
        "    md_lines.append(\"## Documents trait√©s\\n\\n\")\n",
        "\n",
        "    for data in results:\n",
        "        conv = data.get(\"conversion\", {})\n",
        "        md_lines.append(f\"### {data. get('doc_name', '')}\\n\\n\")\n",
        "        md_lines.append(f\"- **Dossier:** `{data.get('doc_folder', '')}`\\n\")\n",
        "        md_lines.append(f\"- **Figures:** {conv.get('figures_count', 0)}\\n\")\n",
        "        md_lines. append(f\"- **R√©f√©rences:** {conv.get('references_count', 0)}\\n\")\n",
        "        md_lines.append(f\"- **Dur√©e:** {data.get('processing_time_seconds', 0)}s\\n\\n\")\n",
        "\n",
        "    with open(report_md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\". join(md_lines))\n",
        "\n",
        "    print(f\"‚úÖ R√©sultats export√©s: \")\n",
        "    print(f\"   üìä Summary: {summary_path}\")\n",
        "    print(f\"   üìù Report: {report_md_path}\")\n",
        "\n",
        "print(\"‚úÖ Fonctions de pipeline d√©finies. \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830ddf11",
      "metadata": {
        "id": "830ddf11"
      },
      "source": [
        "## √âtape 10 ‚Äî Lancer le traitement\n",
        "Ex√©cutez cette cellule pour lancer le traitement complet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c0f8f92",
      "metadata": {
        "id": "4c0f8f92"
      },
      "outputs": [],
      "source": [
        "# Recharger la liste des PDFs depuis INPUT_DIR pour s'assurer qu'elle est √† jour\n",
        "print(\"üìÇ V√©rification du dossier d'entr√©e...\")\n",
        "print(f\"   Chemin: {INPUT_DIR}\")\n",
        "\n",
        "# Recharger la liste des fichiers\n",
        "pdf_files = sorted([p for p in INPUT_DIR.iterdir() if p.suffix.lower() == \".pdf\"])\n",
        "print(f\"   PDFs trouv√©s: {len(pdf_files)}\")\n",
        "\n",
        "if len(pdf_files) == 0:\n",
        "    print(\"\\n‚ö†Ô∏è ATTENTION: Aucun PDF trouv√©!\")\n",
        "    print(\"   V√©rifiez que:\")\n",
        "    print(\"   1. Le chemin INPUT_DIR est correct\")\n",
        "    print(\"   2. Des fichiers PDF sont pr√©sents dans ce dossier\")\n",
        "    print(\"   3. Google Drive est bien mont√©\")\n",
        "else:\n",
        "    for i, pdf in enumerate(pdf_files[:5], 1):\n",
        "        print(f\"   {i}. {pdf.name}\")\n",
        "    if len(pdf_files) > 5:\n",
        "        print(f\"   ... et {len(pdf_files) - 5} autres\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ D√©marrage du pipeline...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results, errors = process_all_documents()\n",
        "\n",
        "if results:\n",
        "    export_all_results(results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ PIPELINE TERMIN√â\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if errors:\n",
        "    print(f\"\\n‚ö†Ô∏è {len(errors)} erreur(s) rencontr√©e(s):\")\n",
        "    for err in errors[:5]:\n",
        "        print(f\"   - {err['file']}: {err['error'][:50]}...\")\n",
        "    if len(errors) > 5:\n",
        "        print(f\"   ... et {len(errors) - 5} autres erreurs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "utils001",
      "metadata": {
        "id": "utils001"
      },
      "source": [
        "## Utilitaires ‚Äî Gestion du cache\n",
        "Cellules optionnelles pour g√©rer le cache des mod√®les sur Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "utils002",
      "metadata": {
        "id": "utils002"
      },
      "outputs": [],
      "source": [
        "# === AFFICHER LA TAILLE DU CACHE ===\n",
        "def show_cache_info():\n",
        "    \"\"\"Affiche les informations sur le cache Drive.\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"üíæ INFORMATIONS CACHE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for name, path in [(\"HuggingFace\", HF_CACHE_DRIVE),\n",
        "                       (\"Torch\", TORCH_CACHE_DRIVE),\n",
        "                       (\"Datalab\", DATALAB_CACHE_DRIVE)]:\n",
        "        size = get_dir_size(path)\n",
        "        print(f\"üìÇ {name}: {size:.2f} GB\")\n",
        "\n",
        "    total = get_dir_size(DRIVE_CACHE_DIR)\n",
        "    print(f\"\\nüì¶ Total: {total:.2f} GB\")\n",
        "    print(f\"üìç Emplacement: {DRIVE_CACHE_DIR}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Appeler la fonction pour afficher les infos\n",
        "show_cache_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "utils003",
      "metadata": {
        "id": "utils003"
      },
      "outputs": [],
      "source": [
        "# === SUPPRIMER LE CACHE (si n√©cessaire) ===\n",
        "# ‚ö†Ô∏è ATTENTION:  Cela supprimera tous les mod√®les en cache!\n",
        "# D√©commentez les lignes ci-dessous pour ex√©cuter.\n",
        "\n",
        "# import shutil\n",
        "#\n",
        "# if DRIVE_CACHE_DIR. exists():\n",
        "#     print(f\"‚ö†Ô∏è Suppression du cache:  {DRIVE_CACHE_DIR}\")\n",
        "#     shutil.rmtree(DRIVE_CACHE_DIR)\n",
        "#     print(\"‚úÖ Cache supprim√©.  Les mod√®les seront ret√©l√©charg√©s au prochain lancement.\")\n",
        "# else:\n",
        "#     print(\"‚ÑπÔ∏è Aucun cache √† supprimer.\")\n",
        "\n",
        "print(\"‚ÑπÔ∏è D√©commentez le code ci-dessus pour supprimer le cache.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}